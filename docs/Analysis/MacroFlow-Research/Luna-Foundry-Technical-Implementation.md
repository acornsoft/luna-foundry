# Leveraging Markdown and JSON in the Luna Foundry

The Luna Foundry leverages Markdown and JSON files as core artifacts for structuring AI-driven development processes, prioritizing Grok/xAI for its truth-seeking, first-principles reasoning while maintaining secondary support for other LLMs to ensure flexibility. Markdown files define agent behaviors, instructions, and skills in human-readable formats, enabling rapid iteration and customization of AI assistants that align with VS Code Copilot standards. JSON files handle structured data like prompts, tool integrations, and configuration schemas, facilitating seamless interoperability with MCP (Model Context Protocol) servers and external tools. This hybrid approach ensures that the Foundry remains lean and extensible, allowing developers to prototype Grok-based agents quickly in Markdown while using JSON for precise, machine-parseable definitions that support multi-LLM fallbacks when Grok's capabilities are supplemented.

At the heart of the Luna Foundry is the MacroFlow process, comprising six disciplined phases—Constitution (establishing foundational principles), Clarify (gathering and refining requirements), Specify (defining technical specifications), Plan (architecting solutions), Tasks (breaking down into actionable items), and Implement (generating production-ready code)—each supported by specialized sub-agents. These sub-agents, defined in Markdown files, act as modular components that can be invoked recursively to deepen analysis, such as a Clarify Agent probing ambiguities or a Plan Agent outlining architectures. Skills, bundled as self-contained Markdown and JSON folders, encapsulate domain expertise (e.g., Azure architecture or Python development), while tools integrate external APIs or MCP servers for data retrieval and execution. This structure enables thorough, Grok-based workflows: starting with truth-seeking clarification to eliminate assumptions, progressing through specification and planning to ensure alignment with client needs, and culminating in lean implementation that minimizes waste through automated scaffolding and deployment scripts.

For solution development, the Foundry's process is designed to be "lean, mean, and truth-seeking," emphasizing first-principles thinking to cut through complexity and deliver high-fidelity outcomes. By leveraging sub-agents for iterative refinement—such as deploying a Specify Agent to validate JSON schemas against Grok's outputs—teams can conduct exhaustive analysis and requirements gathering without over-engineering. Skills and tools further enhance this by providing reusable, truth-verified components for common tasks like code generation or testing, ensuring that deployments are scaffolded efficiently via Azure Functions or local testing environments. This approach not only accelerates client-based solutioning but also maintains fidelity to Grok's principles, using secondary LLMs only for gap-filling, resulting in robust, scalable AI applications that prioritize accuracy and efficiency over unnecessary elaboration.
